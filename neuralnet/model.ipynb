{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e099ca0a-b759-4eba-9802-ce29e53e954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e99b0ba1-ecf2-4416-aa7e-a87c8c325268",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "\n",
    "def init(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)\n",
    "    weights = {\n",
    "        'W1': np.random.randn(hidden_size, input_size) * 0.01,\n",
    "        'b1': np.zeros((hidden_size, 1)),\n",
    "        'W2': np.random.randn(output_size, hidden_size) * 0.01,\n",
    "        'b2': np.zeros((output_size, 1))\n",
    "    }\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd6f0fe6-7acd-47a1-ba7f-4b70dcf345af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = init(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5aac6a8-6a4d-4ca5-9d39-aa055ed3c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e930dcab-7ce8-4cc7-9cf9-e84599345f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, weights):\n",
    "    W1, b1 = weights[\"W1\"], weights[\"b1\"]\n",
    "    W2, b2 = weights[\"W2\"], weights[\"b2\"]\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2)\n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0604a046-57dc-44f5-9fc8-cc20ca8f8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(Y, A2):\n",
    "    m = Y.shape[1]\n",
    "    loss = -1/m * np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0ce85a2-93a4-44fc-b36d-8ab459fa0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X, Y, cache):\n",
    "    (Z1, A1, W1, b1, Z2, A2, W2, b2) = cache\n",
    "    m = X.shape[1]\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = 1/m * np.dot(dZ2, A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (A1 > 0)\n",
    "    dW1 = 1/m * np.dot(dZ1, X.T)\n",
    "    db1 = 1/m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    gradients = {\n",
    "        'dW1': dW1,\n",
    "        'db1': db1,\n",
    "        'dW2': dW2,\n",
    "        'db2': db2\n",
    "    }\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ae0aeb2-077a-4429-803e-1cd05eae264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(weights, gradients, lr):\n",
    "    weights[\"W1\"] -= lr * gradients[\"dW1\"]\n",
    "    weights[\"b1\"] -= lr * gradients[\"db1\"]\n",
    "    weights[\"W2\"] -= lr * gradients[\"dW2\"]\n",
    "    weights[\"b2\"] -= lr * gradients[\"db2\"]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8be20a9-f370-431a-9eab-e67c06767463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931\n",
      "Epoch 10, Loss: 0.6931\n",
      "Epoch 20, Loss: 0.6931\n",
      "Epoch 30, Loss: 0.6931\n",
      "Epoch 40, Loss: 0.6931\n",
      "Epoch 50, Loss: 0.6931\n",
      "Epoch 60, Loss: 0.6931\n",
      "Epoch 70, Loss: 0.6931\n",
      "Epoch 80, Loss: 0.6931\n",
      "Epoch 90, Loss: 0.6931\n",
      "Epoch 100, Loss: 0.6931\n",
      "Epoch 110, Loss: 0.6931\n",
      "Epoch 120, Loss: 0.6931\n",
      "Epoch 130, Loss: 0.6931\n",
      "Epoch 140, Loss: 0.6931\n",
      "Epoch 150, Loss: 0.6931\n",
      "Epoch 160, Loss: 0.6931\n",
      "Epoch 170, Loss: 0.6931\n",
      "Epoch 180, Loss: 0.6931\n",
      "Epoch 190, Loss: 0.6931\n",
      "Epoch 200, Loss: 0.6931\n",
      "Epoch 210, Loss: 0.6931\n",
      "Epoch 220, Loss: 0.6931\n",
      "Epoch 230, Loss: 0.6931\n",
      "Epoch 240, Loss: 0.6931\n",
      "Epoch 250, Loss: 0.6931\n",
      "Epoch 260, Loss: 0.6931\n",
      "Epoch 270, Loss: 0.6931\n",
      "Epoch 280, Loss: 0.6931\n",
      "Epoch 290, Loss: 0.6931\n",
      "Epoch 300, Loss: 0.6931\n",
      "Epoch 310, Loss: 0.6930\n",
      "Epoch 320, Loss: 0.6930\n",
      "Epoch 330, Loss: 0.6930\n",
      "Epoch 340, Loss: 0.6930\n",
      "Epoch 350, Loss: 0.6930\n",
      "Epoch 360, Loss: 0.6929\n",
      "Epoch 370, Loss: 0.6929\n",
      "Epoch 380, Loss: 0.6929\n",
      "Epoch 390, Loss: 0.6928\n",
      "Epoch 400, Loss: 0.6928\n",
      "Epoch 410, Loss: 0.6927\n",
      "Epoch 420, Loss: 0.6927\n",
      "Epoch 430, Loss: 0.6926\n",
      "Epoch 440, Loss: 0.6925\n",
      "Epoch 450, Loss: 0.6924\n",
      "Epoch 460, Loss: 0.6923\n",
      "Epoch 470, Loss: 0.6922\n",
      "Epoch 480, Loss: 0.6920\n",
      "Epoch 490, Loss: 0.6919\n",
      "Epoch 500, Loss: 0.6917\n",
      "Epoch 510, Loss: 0.6914\n",
      "Epoch 520, Loss: 0.6912\n",
      "Epoch 530, Loss: 0.6909\n",
      "Epoch 540, Loss: 0.6905\n",
      "Epoch 550, Loss: 0.6902\n",
      "Epoch 560, Loss: 0.6897\n",
      "Epoch 570, Loss: 0.6892\n",
      "Epoch 580, Loss: 0.6886\n",
      "Epoch 590, Loss: 0.6879\n",
      "Epoch 600, Loss: 0.6871\n",
      "Epoch 610, Loss: 0.6862\n",
      "Epoch 620, Loss: 0.6852\n",
      "Epoch 630, Loss: 0.6840\n",
      "Epoch 640, Loss: 0.6828\n",
      "Epoch 650, Loss: 0.6813\n",
      "Epoch 660, Loss: 0.6795\n",
      "Epoch 670, Loss: 0.6778\n",
      "Epoch 680, Loss: 0.6753\n",
      "Epoch 690, Loss: 0.6729\n",
      "Epoch 700, Loss: 0.6704\n",
      "Epoch 710, Loss: 0.6676\n",
      "Epoch 720, Loss: 0.6640\n",
      "Epoch 730, Loss: 0.6602\n",
      "Epoch 740, Loss: 0.6562\n",
      "Epoch 750, Loss: 0.6521\n",
      "Epoch 760, Loss: 0.6470\n",
      "Epoch 770, Loss: 0.6408\n",
      "Epoch 780, Loss: 0.6367\n",
      "Epoch 790, Loss: 0.6291\n",
      "Epoch 800, Loss: 0.6239\n",
      "Epoch 810, Loss: 0.6181\n",
      "Epoch 820, Loss: 0.6112\n",
      "Epoch 830, Loss: 0.6035\n",
      "Epoch 840, Loss: 0.5970\n",
      "Epoch 850, Loss: 0.5907\n",
      "Epoch 860, Loss: 0.5846\n",
      "Epoch 870, Loss: 0.5774\n",
      "Epoch 880, Loss: 0.5712\n",
      "Epoch 890, Loss: 0.5663\n",
      "Epoch 900, Loss: 0.5567\n",
      "Epoch 910, Loss: 0.5547\n",
      "Epoch 920, Loss: 0.5487\n",
      "Epoch 930, Loss: 0.5427\n",
      "Epoch 940, Loss: 0.5387\n",
      "Epoch 950, Loss: 0.5354\n",
      "Epoch 960, Loss: 0.5277\n",
      "Epoch 970, Loss: 0.5271\n",
      "Epoch 980, Loss: 0.5214\n",
      "Epoch 990, Loss: 0.5181\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "def train(X, Y, input_size, hidden_size, output_size, epochs, lr):\n",
    "    weights = init(input_size, hidden_size, output_size)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        A2, cache = forward_propagation(X, weights)\n",
    "\n",
    "        loss = compute_loss(Y, A2)\n",
    "\n",
    "        gradients = backpropagation(X, Y, cache)\n",
    "\n",
    "        weights = update_parameters(weights, gradients, lr)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {i}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])  # Input data (4 examples, 2 features)\n",
    "Y = np.array([[0, 1, 1, 0]])  # XOR output labels\n",
    "\n",
    "# Train the network\n",
    "trained_weights = train(X, Y, input_size, hidden_size, output_size, epochs=1000, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67f1cf60-a38c-42e0-8168-828a7cfabd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[ True  True  True False]]\n"
     ]
    }
   ],
   "source": [
    "def predict(X, weights):\n",
    "    A2, _ = forward_propagation(X, weights)\n",
    "    predictions = A2 > 0.5\n",
    "    return predictions\n",
    "\n",
    "# Make predictions\n",
    "predictions = predict(X, trained_weights)\n",
    "print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdea6d-5f89-4bdf-b143-6221e3b6f002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b028b8-bf74-4fc0-8698-4143f804f5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971b86b-3592-4a7c-9c2e-2cd4f070453f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
